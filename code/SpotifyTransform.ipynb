{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c0c218-e095-4bd7-8762-a072150af385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b35390-acfc-4774-9222-c0475c7f8912",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "track_spark_df = spark.read.format(\"parquet\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(\"/mnt/spotifydata/to_be_processed/track\")\n",
    "\n",
    "artist_spark_df = spark.read.format(\"parquet\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(\"/mnt/spotifydata/to_be_processed/artist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e618cec-4616-40dd-8a7e-a26bc119e0a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "one_big_table = track_spark_df.join(artist_spark_df, track_spark_df.artist_id == artist_spark_df.artist_id, \"left\").drop(track_spark_df.artist_id)\n",
    "one_big_table = one_big_table.dropDuplicates([\"track_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "308f4cb3-2aae-45dd-8c22-1da1f30d4295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Upsert tracks to delta table\n",
    "delta_table_path = \"/mnt/spotifydata/reporting_data/\"\n",
    "is_merge_track = False\n",
    "\n",
    "if DeltaTable.isDeltaTable(spark, delta_table_path) == False:\n",
    "    # If the table does not exist, create it\n",
    "    one_big_table.write.format(\"delta\").save(delta_table_path)\n",
    "    print(\"Delta table created successfully.\")\n",
    "else:\n",
    "    delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "    \n",
    "    # Define merge condition and update logic\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        one_big_table.alias(\"source\"),\n",
    "        \"target.track_id = source.track_id\"\n",
    "    ).whenMatchedUpdate(set={\n",
    "        \"track_popularity\": \"source.track_popularity\"\n",
    "    }).whenNotMatchedInsertAll().execute()\n",
    "    print(\"Merge operation completed.\")\n",
    "    is_merge_track = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6199e34-7ef5-4cd5-9e40-0491787b7e76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Update artist popularity and follower to delta table\n",
    "if is_merge_track == True:\n",
    "    delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "    \n",
    "    # Define merge condition and update logic\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        artist_spark_df.alias(\"source\"),\n",
    "        \"target.artist_id = source.artist_id\"\n",
    "    ).whenMatchedUpdate(set={\n",
    "          \"artist_popularity\": \"source.artist_popularity\",\n",
    "          \"artist_follower\": \"source.artist_follower\"\n",
    "    }).execute()\n",
    "    print(\"Merge artist operation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ad9d1d-cf87-485b-8986-d757689d6924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"spotify_track_table\"\n",
    "# Register to catalog\n",
    "\n",
    "# Check if the Delta table is registered in the catalog\n",
    "if spark.catalog.tableExists(table_name) == False:\n",
    "    # If the table is not registered register it\n",
    "    # Register the Delta table in the metastore\n",
    "    spark.sql(f\"CREATE TABLE {table_name} USING DELTA LOCATION '{delta_table_path}'\")\n",
    "    print(f\"Table '{table_name}' created and registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebaebfb6-ce93-4dff-bcad-81a5db28d979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def move_file(source_dir, destination_dir, file_type):\n",
    "\n",
    "    source_dir = source_dir + file_type + '/'\n",
    "    destination_dir = destination_dir + file_type + '/'\n",
    "    \n",
    "    # List all parquet files in the source directory\n",
    "    files = dbutils.fs.ls(source_dir)\n",
    "\n",
    "    # Move each file to the destination directory\n",
    "    for file in files:\n",
    "        if file.name.endswith(\".parquet\"):\n",
    "            source_path = file.path\n",
    "            destination_path = destination_dir + file.name\n",
    "            dbutils.fs.mv(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805dbb6f-c570-4714-a070-68672b35a287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# move raw file to processed folder\n",
    "source_dir = \"/mnt/spotifydata/to_be_processed/\"\n",
    "destination_dir = \"/mnt/spotifydata/processed_data/\"\n",
    "move_file (source_dir, destination_dir, \"track\")\n",
    "move_file (source_dir, destination_dir, \"artist\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2266843992044149,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SpotifyTransform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
